# A Survey of Context Engineering for Large Language Models

**arXiv ID**: [2507.13334](http://arxiv.org/abs/2507.13334v1)
**PDF**: [ダウンロード](http://arxiv.org/pdf/2507.13334v1.pdf)
**著者**: Lingrui Mei, Jiayu Yao, Yuyao Ge, Yiwei Wang, Baolong Bi, Yujun Cai, Jiazhi Liu, Mingyu Li, Zhong-Zhi Li, Duzhen Zhang, Chenlin Zhou, Jiayi Mao, Tianze Xia, Jiafeng Guo, Shenghua Liu
**カテゴリ**: cs.CL
**公開日**: 2025-07-17T17:50:36Z

---

## 要約

## ショートサマリ
本研究は、LLMの推論性能を決定する文脈情報の最適化が、従来のプロンプト設計では不十分で研究が断片化しているという問題を解決します。このため、「Context Engineering（コンテキストエンジニアリング）」という正式な学問分野を導入しました。これは、コンテキストの取得・生成、処理、管理という「基盤コンポーネント」と、RAG、メモリシステム、ツール統合推論、マルチエージェントシステムといった「システム実装」からなる包括的な分類体系を提案し、体系的な最適化を目指します。1400報以上の論文分析の結果、LLMは複雑な文脈を理解する能力は高いものの、同等に洗練された長文生成能力には顕著な限界があるという重大な研究ギャップを明らかにしました。

## 本研究の概要
本研究は、大規模言語モデル（LLM）の性能が推論時に提供される文脈情報に根本的に左右されるという背景に基づいています。従来の単純なプロンプト設計では、現代の複雑なAIシステムが必要とする「情報ペイロードの体系的な最適化」に対応できず、研究領域が細分化・断片化しているという課題がありました。

この課題に対処するため、本研究は「Context Engineering（コンテキストエンジニアリング）」をLLMにおける情報ペイロードの設計、管理、最適化を体系的に行う正式な学問分野として定義し、その目的と背景を明確にしました。

本研究が達成できたことは、LLM向けContext Engineeringに関する初の包括的かつ体系的なサーベイを提供したことです。具体的には、本研究は以下の要素を統合した「統一された構造化分類体系」を提案しました：
1. 「Foundational Components（基盤コンポーネント）」：コンテキストの取得と生成（prompt-based generation、external knowledge acquisition）、コンテキストの処理（long sequence processing、self-refinement、structured information integration）、コンテキストの管理（memory hierarchies、compression、optimization）。
2. 「System Implementations（システム実装）」：Retrieval-Augmented Generation（RAG）、メモリシステム、Tool-Integrated Reasoning（ツール統合推論）、Multi-Agent Systems（マルチエージェントシステム）。

このフレームワークを通じて、本研究は各ドメインの最先端技術、その核となるメカニズム、強み、限界を分析し、分野全体の「技術ロードマップ」を確立しました。さらに、現在のLLMが「複雑なコンテキストを理解する能力は著しい」ものの、「同程度に洗練された長文出力を生成する能力には顕著な限界がある」という「根本的な非対称性」という重要な研究ギャップを明らかにしました。これは将来の研究における明確な優先事項であると指摘し、コンテキスト認識AIの進歩に向けた統一フレームワークを研究者とエンジニア双方に提供することを目的としています。

## 本研究の新規性や貢献
本研究は、大規模言語モデル（LLM）の性能向上に不可欠な文脈（コンテキスト）の設計、管理、最適化に関する研究分野の「断片化」という現状の課題を解決します。既存の先行研究は、プロンプトエンジニアリング、RAG、メモリシステムなど、特定の「垂直ドメイン（vertical domains）」に焦点を当てたサーベイが多く、各技術間の「根本的なつながり（fundamental connections）」が暗黙的であるか、未探求のままでした。例えば、RAGが外部メモリの一形態であることや、ツール利用が文脈取得の方法であること、プロンプトエンジニアリングがこれらを統合する言語であるといった相互関係は十分に体系化されていませんでした。

本研究の新規性と貢献は、この断片化された現状に対し、「Context Engineering（コンテキストエンジニアリング）」という「統一的な抽象化（unifying abstraction）」を提案し、そのための「包括的な構造化分類体系」を初めて提示した点にあります。この分類体系は、Context Engineeringを「Foundational Components（基盤コンポーネント）」と「System Implementations（システム実装）」に明確に区別し、多様な技術を単一の首尾一貫したフレームワークに整理します。

これにより、本研究はLLM向けContext Engineering分野の「技術ロードマップ（technical roadmap）」と「統一フレームワーク（unified framework）」を確立し、各技術のメカニズム、強み、限界を体系的に分析します。特に、LLMが「複雑なコンテキストを理解する能力」と「同程度に洗練された長文出力を生成する能力」の間に「根本的な非対称性（a fundamental asymmetry）」が存在するという「重大な研究ギャップ（critical research gap）」を明らかにしました。これは、Context Engineeringを「プロンプト設計の『芸術』から情報ロジスティクスとシステム最適化の『科学』へと転換させる」ものとして位置づけ、将来の研究の明確な優先事項を示しています。

## 手法
本研究は、大規模言語モデル（LLM）におけるContext Engineeringの現状と課題を体系的に整理するために、サーベイ（調査）というアプローチを採用しています。

**研究のアプローチや方法論の概要**:
本研究の主要な貢献は、「包括的な分類体系（comprehensive taxonomy）」の導入です。この分類体系は、Context Engineeringをその「基盤コンポーネント（foundational Components）」と、それらをインテリジェントなシステムに統合する「洗練された実装（sophisticated Implementations）」に分解します。このフレームワークを通じて、論文は1400報以上の研究論文を体系的に分析し、各ドメインの最先端技術、核となるメカニズム、強み、限界を分析しました。

**特徴的な技術や手法の詳細**:
1.  **Context Engineeringの形式的な定義**: 本研究は、従来のプロンプトエンジニアリングとは一線を画し、Context EngineeringをLLMの情報ペイロードの「体系的な最適化」を行う正式な分野として再概念化します。LLMは入力コンテキスト `C` に基づいて出力 `Y` を生成しますが、この `C` を「動的に構造化された情報コンポーネントの集合」として捉え、「`C = A(c1, c2, . . . , cn)`」と定義します。ここで `A` は、プロンプト内の指示（`cinstr`）、外部知識（`cknow`）、利用可能なツールの定義（`ctools`）、過去の対話からの永続的な情報（`cmem`）、ユーザーやシステムの動的な状態（`cstate`）、およびユーザーの即時要求（`cquery`）といった情報コンポーネントをソース、フィルタリング、フォーマットし、最終的に「高レベルのアセンブリ関数」としてオーケストレーションします。
2.  **最適化問題としての定式化**: Context Engineeringは、「LLMの出力の期待品質を最大化する理想的な文脈生成関数 `F` を見つける」という「形式的な最適化問題」として定義されます。目的関数は「`F∗=arg max F Eτ∼T[Reward (Pθ(Y|CF(τ)),Y∗ τ)]`」と示され、特定のタスクインスタンス `τ` に対して関数 `F` が生成するコンテキスト `CF(τ)` を用いたLLMの出力 `Pθ(Y|CF(τ))` の報酬を最大化します。この最適化は、モデルのコンテキスト長制限「`|C| ≤Lmax`」という厳密な制約に従います。
3.  **Bayesian Context Inference（ベイズ的文脈推論）の導入**: 決定論的にコンテキストを構築するのではなく、最適なコンテキストの事後確率「`P(C|cquery, . . .)∝P(cquery|C)・P(C|History, World)`」を推論する概念を導入します。このベイズ定式化は、「不確実性に対応し、事前確率を更新することで適応的な検索を実行し、多段階推論タスクにおいてコンテキストに関する信念状態を維持する」ための原則的な方法を提供すると述べています。

## 評価方法と結果
本研究はサーベイ論文であり、独自の実験や評価は行っていません。しかし、LLM向けContext Engineeringにおける既存の研究成果から、その評価方法と結果に関する重要な洞察を抽出・分析しています。

**実験や評価の方法**:
Context Engineeringシステムの評価は、「Component-Level Assessment（コンポーネントレベル評価）」と「System-Level Integration Assessment（システムレベル統合評価）」の二層に分かれています。
-   **コンポーネントレベル評価**: 各コンポーネントの単体性能を評価します。
    *   **プロンプトエンジニアリング**: 「プロンプト効果の測定、応答品質評価、多様な入力変動に対するロバストネス（堅牢性）テスト」が行われます。
    *   **長文コンテキスト処理**: 「情報保持、位置的バイアス、推論の一貫性」が評価されます。「needle in a haystack」評価パラダイムがモデルが長文コンテキスト内に埋め込まれた特定の情報を検索する能力をテストするのに用いられます。
    *   **自己洗練メカニズム**: 「メタ学習評価、適応速度測定、複数イテレーションにわたる一貫性分析」が行われます。
    *   **構造化データ統合**: 知識グラフの走査、テーブル理解、データベースクエリ生成の精度が評価されます。
-   **システムレベル統合評価**: コンポーネント間の相互作用から生じる「創発的な振る舞い」を捉えるため、下流タスクのエンドツーエンド性能を測定します。
    *   **RAGシステム**: 検索品質と生成効果の両方が、「精度、再現率、関連性、事実の正確性」を含む包括的な指標で評価されます。
    *   **メモリシステム**: 「情報抽出、時間的推論、マルチセッション推論、知識更新」といった長期記憶の基本能力を評価するために、「LongMemEval」などの専用ベンチマークが使用されます。
    *   **ツール統合推論システム**: 「ツール選択の精度、パラメータ抽出の正確性、実行成功率、エラー回復能力」を含む対話軌跡全体が評価されます。「MCP-RADAR」や「GAIA」などのフレームワークが用いられます。
    *   **マルチエージェントシステム**: 「コミュニケーションの有効性、連携の効率性、集合的成果の品質」が、プロトコル順守、タスク分解精度、創発的な協調行動を通じて評価されます。

**得られた結果の概要と解釈**:
体系的な分析を通じて、本サーベイは「モデル能力間に根本的な非対称性が存在」するという「重大な研究ギャップ」を明らかにしました。「現在のモデルは、高度なコンテキストエンジニアリングによって強化されているものの、複雑なコンテキストを理解する能力において顕著な熟練度を示している一方で、同程度に洗練された長文出力を生成する能力には顕著な限界を示しています」。

具体的な結果として、以下の点が挙げられています。
-   **メモリシステム評価**: 商用AIアシスタントは、「長期間の相互作用を通じて約30%の精度劣化」を示すことが「LongMemEval」などのベンチマークで示され、メモリの永続性と検索効果に重大な欠陥があることを浮き彫りにしました。
-   **ツール統合推論システム評価**: 「GAIA」ベンチマークでは、人間が一般アシスタントタスクで「92%の精度」を達成するのに対し、GPT-4などの先進モデルは「15%の精度」しか達成できず、「著しい性能ギャップ」が存在します。これは、現在の評価フレームワークとシステム能力における根本的な限界を示しています。
-   **評価手法の限界**: 従来の「静的な指標（BLEU、ROUGE、perplexity）」では、複雑な推論チェーンや動的な振る舞いを評価するのに根本的に不十分であることが判明しています。多成分システムの複雑性と相互依存性は、「帰属の課題（attribution challenges）」を生み出し、失敗の原因特定を困難にしています。

これらの結果は、LLMの理解能力と生成能力の間の不均衡、および実世界への導入におけるシステムの信頼性と堅牢性の不足を示唆しています。

## 制限事項と課題
本研究はContext Engineeringに関する包括的なサーベイであり、その過程でLLMおよびContext Engineering分野全体にわたる複数の制限事項と未解決の課題を特定し、今後の研究方向性を提示しています。

**研究の限界や未解決の問題**:
1.  **理論的基盤の欠如**: Context Engineeringは現在、「統一された理論的基盤」を欠いており、多様な技術を横断する原則的な設計指針や、異なるアーキテクチャ設定における能力と限界を特徴づける数学的フレームワークが存在しないことが、体系的な進歩と最適なシステム開発を妨げています。
2.  **理解と生成の非対称性**: LLMの「優れた文脈理解能力」と「同程度に洗練された長文出力生成能力の顕著な限界」の間に「根本的な非対称性」が存在します。この「理解-生成ギャップ」は、長文出力の一貫性、事実の一貫性、および計画の洗練度において顕著であり、これがアーキテクチャ上の制約、トレーニング方法、または根本的な計算限界に起因するのか、更なる調査が必要です。
3.  **計算効率のスケーリング限界**: 現行のアテンションメカニズムはシーケンス長に対して「2次関数的な計算量増加（O(n2)）」を示すため、超長文シーケンスの処理には法外なメモリと計算要件が課せられます。これはLLMの実世界展開における大きな障壁となっています。
4.  **マルチモーダル統合と表現の課題**: 異なるモダリティ（例：テキスト、画像、音声、3D環境）の統合は、表現学習、クロスモーダル推論、統一されたアーキテクチャ設計において根本的な課題を提示します。特に、グラフ構造のような抽象的な情報は、LLMが直接解釈することが困難であり、複雑な関係構造をナビゲートする能力が求められます。
5.  **評価手法の限界とバイアス**: 従来の評価指標（BLEU、ROUGE、perplexityなど）は、Context Engineeringシステムの持つ微妙で動的な挙動を捉えるのに不十分です。多成分システムの複雑性により、「原因の特定が困難」である「帰属の課題」が生じます。メモリシステムにおいては「分離問題（isolation problem）」が、ツール統合システムにおいては人間レベルの性能との「著しいギャップ（GAIAベンチマークでGPT-4が15% vs 人間92%）」が指摘されています。

**今後の研究課題や展望**:
1.  **理論的基盤の確立**: 最適なコンテキスト割り当て、情報冗長性の定量化、コンテキストウィンドウ内での圧縮限界に関する情報理論的分析を通じて、統一的な理論的フレームワークを確立することが重要です。
2.  **次世代アーキテクチャの開発**: 線形スケーリング特性を持つ「ステートスペースモデル（State Space Models: SSMs）」や、より高度な長期記憶組織化と適応的メモリ管理戦略を可能にする「メモリ拡張型アーキテクチャ」の進化が必要です。
3.  **高度な推論と計画能力の強化**: 因果推論、反実仮想思考、時間的推論、類推推論など、複雑な推論パターンを統合し、複数段階の計画と実行を可能にする能力の開発が求められます。
4.  **複雑なコンテキストの組織化とグラフ問題の解決**: グラフ構造情報とLLMの埋め込みを連携させる技術や、連想ネットワークを通じて情報を組織化する新しいRAGシステムなど、複雑な関係性を伴うグラフ問題に対応する能力の向上が必要です。
5.  **インテリジェントなコンテキストアセンブリと最適化**: コンテキスト最適化アルゴリズム、適応的選択戦略、学習されたアセンブリ関数の開発により、利用可能なコンポーネントからインテリジェントにコンテキストを構築する自動化されたシステムが求められます。
6.  **大規模マルチエージェントシステムの協調**: 数百から数千のエージェントへのスケーリング、分散協調メカニズム、効率的な通信プロトコル、階層的管理構造の確立が、大規模なマルチエージェント展開における重要な課題です。特に「トランザクションの整合性」と「コンテキスト管理」が重要視されます。
7.  **人間とAIの協調と統合**: 人間の認知プロセス、コミュニケーション選好、信頼ダイナミクスを深く理解し、相補的な強みを持つハイブリッドチームを可能にするフレームワークの開発が必要です。
8.  **安全性、セキュリティ、堅牢性の確保**: 自律的に広範囲にわたって動作するエージェントシステムにおいて、潜在的な失敗モード、安全違反、意図しない挙動を特定するための包括的な評価フレームワークの開発が急務です。

---

*このファイルは自動生成されました。生成日時: 2025年07月18日 08:32:31*
