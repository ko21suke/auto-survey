# EmbRACE-3K: Embodied Reasoning and Action in Complex Environments

**arXiv ID**: [2507.10548](http://arxiv.org/abs/2507.10548v1)
**PDF**: [ダウンロード](http://arxiv.org/pdf/2507.10548v1.pdf)
**著者**: Mingxian Lin, Wei Huang, Yitang Li, Chengjie Jiang, Kui Wu, Fangwei Zhong, Shengju Qian, Xin Wang, Xiaojuan Qi
**カテゴリ**: cs.CV, cs.AI, cs.CL
**公開日**: 2025-07-14T17:59:46Z

---

## 要約

## #0ショートサマリ
本研究は、既存のVision-Language Models（VLM）が受動的な視覚理解には優れるものの、エージェントが環境とオンラインでインタラクションし、行動が次の観察を動的に形成する「身体化された（embodied）」設定での空間推論や長期計画に限界があるという問題に取り組んでいます。この課題を解決するため、Unreal EngineとUnrealCV-Zooフレームワークで構築された、多様でフォトリアリスティックな環境における3,000以上の言語誘導タスクを含む新しいデータセット「EmbRACE-3K」を導入しました。各タスクは、一人称視点からの観察、高レベル指示、具象化されたアクション、自然言語によるステップごとの思考プロセスを特徴とするマルチステップの軌跡として展開されます。EmbRACE-3Kを用いたベンチマークでは、GPT-4oやGemini 2.5 Proなどの最先端モデルでさえ、ゼロショット設定で成功率が20%未満と低いことを示し、問題の難しさを浮き彫りにしました。しかし、Qwen2.5-VL-7Bを本データセットで教師あり学習と強化学習を用いてファインチューニングした結果、探索、動的空間意味推論、マルチステージ目標実行の全てのカテゴリで大幅な性能向上が見られ、データセットの有効性が実証されました。

## #1本研究の概要
本研究は、先進的なVision-Language Models（VLM）が受動的な画像・動画理解タスクで強力な性能を発揮する一方で、オンラインでのインタラクションと能動的なシーン理解を必要とする「身体化された（embodied）」設定においてその有効性が限定的であるという課題を解決することを目的としています。このようなシナリオでは、エージェントは一人称視点から環境を知覚し、各アクションがその後の観察を動的に形成するため、既存の最先端モデルでさえ空間推論や長期計画に明確な限界を示していました。

本研究では、このギャップを埋めるために「EmbRACE-3K」というデータセットを導入しました。これは、Unreal EngineとUnrealCV-Zooフレームワークを用いて構築された、多様でフォトリアリスティックな環境に設定された3,000以上の言語誘導タスクを含んでいます。これらのタスクは、ナビゲーション、オブジェクト操作、マルチステージ目標実行といった幅広い身体化された課題を網羅しています。各タスクは、一人称視覚観察、高レベル指示、具象化されたアクション、そしてエージェントの意図を表現する自然言語による思考プロセスを組み合わせたマルチステップの軌跡として展開されます。EmbRACE-3Kを用いて、探索、動的空間意味推論、マルチステージ目標実行という3つの主要な側面でVLMの身体化推論能力を評価するベンチマークを確立しました。ゼロショット設定では、全てのモデルが20%未満の成功率を達成し、ベンチマークがもたらす課題とVLMの現在の限界を浮き彫りにしました。さらに、EmbRACE-3Kの有用性を示すため、Qwen2.5-VL-7Bを教師あり学習と強化学習でファインチューニングした結果、全ての課題カテゴリで大幅な改善が得られ、身体化推論能力の開発を可能にするデータセットの有効性が強調されました。

## #2本研究の新規性や貢献
Vision-Language Models（VLM）は、画像キャプションやビデオ要約といったオフラインの受動的理解タスクで顕著な進歩を遂げています。しかし、エージェントが能動的に環境を知覚し、推論し、行動する必要がある「身体化されたタスク」においては、その有効性が依然として限定的です。これは、エージェントの行動が次の観察を動的に決定する「閉ループの知覚-行動サイクル」が存在するためです。既存のVLMは、一時的な手がかりに過度に適合し、視点の変化に応じて空間推論を調整できず、一時的に視界から外れたオブジェクトに対する注意を維持できないといった一貫した失敗パターンを示しています。

関連する先行研究には、コード生成で推論を扱うOctopusや、事前定義された軌跡に依存するALFREDなどがありますが、これらの多くのベンチマークは、詳細な監視、オンラインインタラクション、または視覚的リアリズムを欠いています。既存のVLMは主に静的または緩く時間的に関連付けられた画像-テキストデータで訓練されており、能動的な探索や自己中心的な姿勢認識の能力が不足しています。

本研究は、このギャップに対処するために、「EmbRACE-3K」という一人称視覚観察、具象化されたアクション、自然言語によるステップごとの思考プロセス（意図説明）を詳細にアノテーションした、3,000以上の言語誘導タスクからなるデータセットを導入しました。このデータセットは、オンラインの閉ループインタラクションをサポートし、知覚と意思決定を密接に連携させる時間的に根拠のあるアノテーションを提供します。さらに、「探索」「動的空間意味推論」「マルチステージ目標実行」の3つの主要な側面でVLMの身体化推論能力を評価する新しいベンチマークを確立しました。このデータセットを用いたQwen2.5-VL-7Bのファインチューニングは、既存のVLMの限界を克服し、身体化推論能力の開発を可能にする有効な基盤を確立することを示しました。

## #3手法
本研究では、VLMの身体化された推論と行動能力を向上させるため、新たなデータセット構築と2段階のファインチューニングフレームワークを提案しました。

まず、データ収集はUnreal EngineとUnrealCV-Zooフレームワークを用いて多様なフォトリアリスティック環境を構築し、以下の4段階で実施されました。
1.  **環境サンプリングとポーズ選択**: Unreal EngineのナビゲーションAPIと手動検証を組み合わせ、エージェントの6-DoF（6自由度）ポーズと一人称視点画像を収集します。
2.  **タスク指示生成**: Gemini 2.5 Proを用いて、一人称視点と周囲のオブジェクトメタデータに基づいて、ナビゲーション、探索、動的空間意味、マルチステージ、インタラクションの5種類のタスク指示を生成します。
3.  **人間デモンストレーションと軌跡キャプチャ**: 人間プレイヤーがリアルタイムでエージェントを操作し、視覚フレーム、実行アクション、ポーズ軌跡を記録します。
4.  **ステップごとの推論アノテーション**: Geminiがタスク指示、全一人称視点、全行動軌跡を受け取り、各行動に対する自然言語での説明（思考プロセス）をアノテーションします。このアノテーションは、「『選択された行動だけでなく、空間構造、タスクの動態、全体的な意図との関連性も捉えています。』」

次に、Qwen2.5-VL-7Bをベースモデルとして、以下の2段階のファインチューニングを行います。
1.  **教師ありファインチューニング（SFT）**: Llama-Factoryフレームワークを用いて、マルチターンの対話形式でQwen2.5-VL-7Bを訓練します。このフェーズは、「『新しい視覚シーンを理解し、行動決定のために推論するモデルの能力を向上させるように設計されました。』」モデルは「<think></think>」タグ内に推論プロセス、「<action></action>」タグ内に最終的な行動決定を出力するように学習されます。
2.  **強化学習（RL）**: GRPO（Group Relative Policy Optimization）フレームワークを適用します。「『このアプローチは、ルールベースの報酬形式<think></think>と<action></action>を組み込むことで、身体化されたエージェントがオープン環境で推論戦略を自由に探索するように導くことを目的としています。』」これにより、行動内容が直接評価され、モデルが最適化されます。

## #4評価方法と結果
本研究では、EmbRACE-3Kデータセットの有効性を評価するため、in-domain（学習環境内）とout-of-domain（学習環境外）の両方で実験を行いました。評価タスクは「Basic」「Exploration」「Dynamic Spatial-Semantic」「Multi-stage」「Interaction - Open Door」「Interaction - Pick and Drop」の6種類です。入力はタスク指示、現在のシーン説明、アクション履歴、現在の視点画像、および直近5フレームと初期フレームで構成されます。ベースラインモデルとしてGPT-4o、Gemini 2.5 Pro、Qwen2.5-VL-originを用い、提案手法としてQwen2.5-VL-sft-rl、Qwen2.5-VL-sft-only、Qwen2.5-VL-no-thinkingを評価しました。評価指標は、成功率（SR）、目標距離誤差（GDE）、経路長に基づく成功効率（SSPL）、ステップ数（Steps）、タイムアウト率（TR）の5つです。

実験結果は以下の通りです。
-   **ゼロショットモデルの課題**: 「『ファインチューニングなしの全モデルにおいて、探索、空間関連、マルチステージタスクでの性能は低いままです。例えば、GPT-4oのアウトオブドメインタスクでの成功率（SR）は、探索でわずか3.6%、動的空間意味で10.2%、マルチステージで2.7%です。』」これは、EmbRACE-3Kがゼロショットモデルにとって大きな挑戦であることを示しています。
-   **SFTとRLによる性能向上**: Qwen2.5-VLをEmbRACE-3Kでファインチューニングすると、全タスクタイプで大幅な改善が見られました。「『表2において、sft-rlバリアントは、アウトオブドメインの探索タスクで30.9%のSR、空間意味タスクで42.4%のSRを達成し、いずれもGPT-4oとGemini 2.5 Proを上回っています。特に、そのGDEは探索で9978.3以上から1162.8に、空間意味で7844.0から824.6に減少しています。』」
-   **推論アノテーションの貢献**: 「no-thinking」モデルとの比較により、思考プロセスのアノテーションが意思決定の質を向上させることを示唆しています。「『動的空間意味（インドメイン）において、SRは27.1%（no-thinking）から42.4%に改善し、SSPLは0.268から0.405に増加しています。同様に、マルチステージタスクでは、no-thinking（10.8%）とsft-only（18.9%）の間のSRの差は、意思決定ステップが言語的な根拠と対になっている場合に、より安定した連続的な行動を示すことを示しています。これらの結果は、ステップごとの推論監視が空間的な根拠付けとタスクのコンテキスト維持に役立つことを示唆しています。』」
-   **汎化能力の課題とRLの有効性**: SFTのみのモデルはin-domainでは良好なパフォーマンスを示すものの、out-of-domainで性能が大きく低下します。対照的に、RLを組み合わせたモデルはより良い汎化能力を示しました。「『これは、軌跡レベルの強化学習信号が、空間レイアウトやオブジェクト構成が訓練環境と異なる未見のシーンでの方策の堅牢性を促進するという我々の仮説を裏付けています。』」

## #5制限事項と課題
本研究は身体化された推論と行動におけるVLMの限界に対処するための重要な進歩を遂げましたが、いくつかの制限事項と今後の課題が残されています。

研究の限界として、教師ありファインチューニング（SFT）のみで訓練されたモデルは、in-domainタスクでは良好なパフォーマンスを示すものの、「『out-of-domainシナリオでは顕著な性能劣化を示します。』」これは、モデルが訓練データに見られる特定の空間レイアウトやオブジェクト構成に過度に適合し、未知の環境への汎化能力が依然として課題であることを示しています。強化学習（RL）を導入することでこの汎化能力は向上しましたが、完全に解決されたわけではありません。

今後の研究課題としては、「『それはまた、そのような設定でのトレーニングをサポートするための高品質でインタラクション中心のデータセットの差し迫った必要性を強調しており、EmbRACE-3Kは特に貢献できる分野です。』」と述べられているように、データセットのさらなる拡張と多様化が重要です。また、「『ベンチマーク実験は、空間推論、長期計画、因果理解における重大な課題を明らかにし、身体化された推論の進歩におけるデータセットの価値を強調している。』」ことから、これらの領域におけるVLMの能力をさらに強化する手法の開発が求められます。EmbRACE-3Kは、「『時間的な汎化を可能にし、知覚と言語誘導行動を統合することで、EmbRACE-3Kは、実世界アプリケーションが可能なインテリジェントエージェントの開発の基盤を確立する。』」と位置づけられており、将来の実世界応用に向けて、より堅牢で適応性の高いエージェントを開発するための基盤となることが期待されます。

---

*このファイルは自動生成されました。生成日時: 2025年07月15日 08:32:27*
