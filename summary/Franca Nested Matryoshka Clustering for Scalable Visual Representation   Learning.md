# Franca: Nested Matryoshka Clustering for Scalable Visual Representation   Learning

**arXiv ID**: [2507.14137](http://arxiv.org/abs/2507.14137v1)
**PDF**: [ダウンロード](http://arxiv.org/pdf/2507.14137v1.pdf)
**著者**: Shashanka Venkataramanan, Valentinos Pariza, Mohammadreza Salehi, Lukas Knobel, Spyros Gidaris, Elias Ramzi, Andrei Bursuc, Yuki M. Asano
**カテゴリ**: cs.CV
**公開日**: 2025-07-18T17:59:55Z

---

## 要約

## ショートサマリ
本研究は、既存の最先端ビジョン基盤モデルがプロプライエタリなデータに依存し、透明性や再現性に欠ける課題を解決します。このため、完全にオープンソース（データ、コード、重み）のビジョン基盤モデル「Franca」を提案し、Web-SSLに触発された透明な学習パイプラインと公開データ（ImageNet-21K、ReLAION-2Bのサブセット）を使用しました。さらに、SSLクラスタリング手法におけるセマンティクスの曖昧さに対処するため、ネストされたマトリョーシカ表現に基づくパラメータ効率の良いマルチヘッドクラスタリングプロジェクターを導入し、モデルサイズを増やすことなく特徴をきめ細かく精製します。また、密な表現から位置バイアスを明示的に除去する新しい位置分離戦略（RASA）を提案しました。Francaは、分類、セグメンテーション、OOD検出、3D理解など多様なベンチマークにおいて、DINOv2やCLIPなどの既存のプロプライエタリモデルの性能に匹敵し、多くの場合で上回る結果を示し、再現性と汎用性のある基盤モデルの新しい標準を確立しました。

## 本研究の概要
本研究の目的は、強固でロバストな大規模ビジョンモデルの開発における課題、特に既存の最先端モデルがプロプライエタリなデータセットに依存している点に対処することです。DINOv2、SEER、SigLIPv2などのモデルは、アクセス不能なデータで学習されており、再現性、アクセス可能性、科学的進歩に大きな障壁となっています。このギャップを埋めるため、私たちは、完全にオープンソース（データ、コード、重み、中間チェックポイント）のビジョン基盤モデル「Franca」を提案しました。

Francaは、Web-SSLから着想を得た透明性の高い学習パイプラインを採用し、ImageNet-21KとReLAION-2Bのサブセットといった公開データのみを使用しています。これにより、既存のプロプライエタリモデルに匹敵し、多くの場合で性能を上回ることを達成しました。また、モデルの公開に加え、自己教師あり学習（SSL）クラスタリング手法の重要な限界、すなわち「クラスタリングのセマンティクスに内在する曖昧さ」と、密な表現における「位置バイアス」の問題を解決しました。Francaは、透明性の高い高性能なビジョンモデルの新しい標準を確立し、より再現性と汎用性のある基盤モデルへの道を開くものです。

## 本研究の新規性や貢献
大規模ビジョンモデルは、3DシステムやマルチモーダルLLMの不可欠な構成要素ですが、現状の最先端モデル（DINOv2, CLIP, SigLIPv2など）はプロプライエタリなデータセットに依存しており、再現性、アクセス可能性、科学的進歩を妨げています。これは研究コミュニティにとって、モデルの新規性や学習戦略の真の影響をデータセットの特性から分離することを困難にしています。

さらに、DINOv2のようなクラスタリングベースのSSL手法は、固定された粒度での割り当てにおける内在的な曖昧さを考慮しておらず、極めて大規模なコードブックを使用しても特定のドメインにしか適さない場合があります。また、密な表現では、画像パッチの絶対的な位置情報がセマンティックな内容と絡み合ってしまう「位置バイアス」という問題が存在します。

本研究は、これらの課題に対し、以下の主要な貢献を行います。第一に、既存のプロプライエタリモデルと同等以上の性能を持つ、初の「完全にオープンソース（データ、コード、重み）のビジョン基盤モデル『Franca』」を提案し、透明性と再現性の新しい標準を確立します。第二に、パラメータ効率の良い「ネストされたマルチヘッドクラスタリングプロジェクター（マトリョーシカ表現）」を導入し、モデルサイズを増やすことなくきめ細かなクラスタリングを可能にすることで、クラスタリングの曖昧さに対処し、表現品質を効率的に向上させます。第三に、「空間・セマンティック分離（RASA）」という後処理手法を開発し、表現から位置バイアスを効果的に除去し、よりクリーンな特徴空間を実現することで、様々なダウンストリームタスクで一貫した性能向上を達成しました。

## 手法
Francaは、「iBoT [Zhou et al., 2022b] と大規模公開画像データセットに基づいて構築された、スケーラブルなオープンソース自己教師あり学習フレームワーク」です。本研究では、「既存のビジョンSSLモデルにおける主要な限界を3つの主要コンポーネントで解決」しています。

研究のアプローチとして、DINOのマルチクロップトレーニング戦略を踏襲し、Vision Transformer (ViT) をバックボーンとして使用します。学生モデルの埋め込みにはプロジェクションヘッドが適用され、教師モデルの出力は「Sinkhorn-Knopp [Cuturi, 2013] を用いてクラスタリングされ、バランスの取れたターゲット分布を生成」します。学生モデルは、これらのターゲットにクロスエントロピー損失でマッチするように学習されます。

特徴的な技術は以下の3点です。
1.  **Matryoshka Representations for Efficient Multi-Granular Learning**: 標準的なMatryoshkaアプローチを拡張し、「各サブスペースに専用のプロジェクションヘッドとクラスタリング目的関数をアタッチ」することで、各スライスが異なるプロトタイプとプロトタイプ割り当てを生成し、表現の粒度に応じた特化を促進します。また、「プロトタイプの数をサブスペースのサイズに比例して減らすことで、特徴の粒度と自然に整合する階層的なクラスタリング」を可能にします。全体の損失は、「Ltotal=kΣi=1L(i)」として全てのレベルの合計です。
2.  **Balancing Spatial Distribution of Visible Patches with CyclicMask**: マスクされた画像モデリング（MIM）のマスキング戦略における空間的偏りを解決するため、「CyclicMask を導入」します。これは、「逆ブロックマスキングからのマスクを、学習中に両空間軸に沿って円形にシフトさせる」ことで、「連続した可視領域の利点を保ちながら、全てのパッチ位置にわたる均一な露出を保証し、位置バイアスを排除」します。
3.  **RASA (Removal of Absolute Spatial Attributes)**: 訓練済みのモデルのパッチ埋め込みから位置情報を分離する後処理戦略です。「位置バイアスを軽減するため、絶対空間属性の除去（RASA）を提案」し、「潜在空間を位置情報と直交するものに投影」することで、位置予測に寄与する特徴空間の次元を抑制します。このプロセスは反復的に行われ、残りの位置平面が次のサブスペースを生成するのに用いられます。「これは反復的な洗練であり、各反復tで、残りの位置平面psが次のサブスペースZsを生成するのに使用されます。」

## 評価方法と結果
Francaは、ImageNet-21KとLAION-600M（ReLAION-2Bのサブセット）の公開データセットでViT-B、ViT-L、ViT-Gモデルを500エポック学習し、MatryoshkaとRASAを適用しました。評価は画像分類（線形プロービング、ロバストネス、ファイングレイン分類）、自己アテンションマップとPCAによるパッチ特徴の可視化、密なタスク（In-Context Learning、線形セグメンテーション、オーバークラスタリング、非教師ありオブジェクト発見）、および3D理解（キーポイント対応、単眼深度推定、Gaussian Splatting）といった多岐にわたるベンチマークで行われました。

得られた結果は以下の通りです。画像分類では、「Franca はDINOv2に匹敵する性能を達成し、はるかに大規模なデータセットで訓練されたWeb-SSL [Fan et al., 2025] を上回」り、DINOv2の多くの強みが蒸留に依存することを示唆しました。ロバストネス評価では、「Franca は、大規模および巨大モデルのバリアント全体で一貫してDINOv2を上回」り、分布シフトに対する堅牢性を示しました。ファイングレイン分類では、「ViT-G/14モデル（Franca-G）はDINOv2-Gと同じ性能を達成し、より少ないデータで訓練されているにもかかわらずWeb-SSL-Gを1.1%上回」りました。PCAの可視化では、「Franca は、実際のオブジェクトと整合した密でまとまりのあるカラーセグメントを生成」し、DINOv2よりも優れたオブジェクト境界の検出を示しました。

密なタスクでは、In-Context Learningにおいて「Franca は一貫して強力なセグメンテーション結果を達成」し、ViT-G/14スケールではDINOv2-Gを上回りました。線形セグメンテーションでは、「Franca は一貫して先行手法に匹敵するか、それを上回」り、ViT-G/14で全てのベンチマークで最高の性能を達成しました。オーバークラスタリングでは、「Franca は、バックボーンとクラスターサイズ全体で強力で一貫した性能を示し、ViT-G/14スケールで最大のゲイン」を得ました。

3D理解において、「Franca は両方のタスクで強力な性能を達成し、DINOv2（IN-21Kで再現）を上回り、同規模のOpen-CLIPおよびSigLIPv2ベースラインを凌駕」しました。特にSPair-71kでは、DINOv2（蒸留版）をViT-Lで3%、ViT-Gで1.5%上回りました。Gaussian Splattingを用いたプロービングでは、「Franca は幾何学的認識において、また完全な設定（All）で評価された場合も、最高の性能を発揮し、強力な幾何学的認識を示唆」しました。これらの結果は、Francaが公開データとオープンな手法のみで、最先端のモデルに匹敵またはそれを凌駕する性能を持つことを明確に示しています。

## 制限事項と課題
本研究は、オープンソースのビジョン基盤モデル「Franca」を提示し、その優れた性能を示しましたが、いくつかの制限事項や、今後の研究で探求すべき課題も存在します。

一つの制限事項は、データセットのドメインギャップに起因する可能性のある性能差です。例えば、LAION-600Mで学習したFrancaのSigLIPv2との比較では、「LAION-600MバリアントのFrancaはわずかに性能が劣る」と述べられており、「これは事前学習の分布とImageNet評価ベンチマーク間のドメインギャップに起因する」と考察されています。これは、将来的に事前学習データのキュレーションやアライメントをさらに最適化する余地があることを示唆しています。

また、計算リソースの制約も指摘されています。「計算上の制約により、高解像度でのファインチューニングはベースモデルのみで行われました。」これは、より大規模なモデル（ViT-LやViT-G）での高解像度ファインチューニングの可能性が未探索であり、今後の性能向上に繋がる潜在的な課題と言えます。

論文の結論部分では、今後の具体的な研究課題が明記されていませんが、Francaが「より再現性と汎用性のある基盤モデルへの道を開く」と述べており、今後もオープンで透明性の高い研究を通じて、AIコミュニティ全体に貢献していく展望が示されています。

---

*このファイルは自動生成されました。生成日時: 2025年07月21日 08:36:29*
