# The Devil behind the mask: An emergent safety vulnerability of Diffusion   LLMs

**arXiv ID**: [2507.11097](http://arxiv.org/abs/2507.11097v1)
**PDF**: [ダウンロード](http://arxiv.org/pdf/2507.11097v1.pdf)
**著者**: Zichen Wen, Jiashu Qu, Dongrui Liu, Zhiyuan Liu, Ruixi Wu, Yicun Yang, Xiangqi Jin, Haoyun Xu, Xuyang Liu, Weijia Li, Chaochao Lu, Jing Shao, Conghui He, Linfeng Zhang
**カテゴリ**: cs.CL
**公開日**: 2025-07-15T08:44:46Z

---

## 要約

## ショートサマリ
本研究は、拡散ベース大規模言語モデル（dLLM）において、既存の安全性アライメントメカニズムが、コンテキストを考慮したマスク入力の敵対的プロンプトに対して脆弱であるという根本的な安全上の懸念を特定しました。この問題に対処するため、本研究はdLLMの固有の安全上の弱点、すなわち双方向性モデリングと並列デコーディングを悪用する初の系統的なジェイルブレイク攻撃フレームワーク「DIJA」を提案します。DIJAは、マスクとテキストを交互に配置した敵対的プロンプトを構築し、モデルに有害な内容を文脈的に一貫して生成させます。包括的な実験により、DIJAは既存のジェイルブレイク手法を大幅に上回り、Dream-Instructで最大100%のキーワードベースASR（Attack Success Rate）を達成しました。この手法は、有害なコンテンツをプロンプト内で書き換えたり隠したりする必要がない点が特筆されます。

## 本研究の概要
本研究は、高速な推論と双方向性モデリングによる高いインタラクティブ性を提供する、自己回帰型LLMの強力な代替手段として台頭している拡散ベース大規模言語モデル（dLLM）が抱える、根本的な安全上の懸念を明らかにすることを目的としています。具体的には、dLLMの既存の安全性アライメントメカニズムが、コンテキストを考慮したマスク入力の敵対的プロンプトに対して機能せず、新たな脆弱性を露呈させることを特定しました。

本研究で達成できたことは、これらのdLLMの固有の安全上の弱点を悪用する初の系統的な研究およびジェイルブレイク攻撃フレームワーク「DIJA」を提案したことです。DIJAは、dLLMのテキスト生成メカニズムである双方向性モデリングと並列デコーディングを悪用して、敵対的なマスクとテキストを交互に配置したプロンプトを構築します。これにより、モデルは有害な場合でもマスクされたスパンに対して文脈的に一貫した出力を生成し、並列デコーディングが安全でないコンテンツの動的フィルタリングとリジェクションサンプリングを制限するため、標準的なアライメントメカニズムが機能不全に陥ります。結果として、アライメントチューニングされたdLLMであっても、プロンプトに有害な行動や安全でない指示が直接含まれている場合に、有害な内容を生成させることが可能になりました。

## 本研究の新規性や貢献
拡散ベース大規模言語モデル（dLLM）は、自己回帰型LLM（AR-LLM）の有望な代替パラダイムとして登場し、コード生成やテキスト補完などのタスクで高い性能を示しています。しかし、「The jailbreak safety of diffusion-based LLMs remains largely unexplored, leaving an important open problem for future research.」とあるように、AR-LLMとは異なる生成メカニズム（双方向性コンテキストモデリングと並列デコーディング）を持つdLLMの安全性、特にジェイルブレイク攻撃に対する脆弱性については、これまで体系的に研究されていませんでした。既存のジェイルブレイク攻撃手法（GCG、AutoDAN、PAIRなど）や防御手法は、主にAR-LLM向けに開発されており、dLLMの特性に起因する新しい脆弱性に対応できていないという限界がありました。

本研究は、dLLMの安全問題に関する初の調査であり、この分野における重要な位置づけを確立します。具体的な貢献は以下の通りです。
1.  「To the best of our knowledge, this is the first investigation into the safety issues of dLLMs.」と述べられているように、dLLMの双方向性および並列デコーディングメカニズムに起因する新しい攻撃経路を特定し、その特性を明らかにしました。
2.  既存の通常のジェイルブレイクプロンプトを、dLLM上で有害な出力を引き出すことが可能な、マスクとテキストを交互に配置したジェイルブレイクプロンプトに変換する自動化された攻撃パイプライン「DIJA」を提案しました。
3.  包括的な実験を通じて、DIJAが複数のdLLMと既存の攻撃手法と比較して効果的であることを実証し、現在のdLLMアライメント戦略における重大なギャップと、即座に対処が必要なセキュリティ上の脆弱性を浮き彫りにしました。

## 手法
本研究は、拡散ベース大規模言語モデル（dLLM）に対する新規のジェイルブレイク攻撃フレームワーク「DIJA」を提案します。この手法は、dLLMの2つの核となる特性、すなわち「bidirectional context modeling」（双方向性コンテキストモデリング）と「iterative parallel demasking」（反復並列デマスキング）を悪用します。

研究のアプローチとして、DIJAは戦略的に設計されたマスクとテキストを交互に配置したプロンプトを通じて、モデルの出力を体系的に操作します。具体的には、「our proposed DIJA constructs adversarial interleaved mask-text prompts that exploit the text generation mechanisms of dLLMs, i.e., bidirectional modeling and parallel decoding.」とあるように、敵対的なマスクとテキストの混合プロンプトを構築します。

この手法の特徴は以下の通りです。
1.  **双方向性コンテキストモデリングの悪用**: dLLMは、マスクされたスパンの周囲のトークンシーケンス全体を見て、全体のコヒーレンスと流暢性を最もよく維持するトークンを埋め込みます。これにより、「Bidirectional modeling drives the model to produce contextually consistent outputs for masked spans, even when harmful.」とあるように、有害な内容であっても文脈的に一貫した出力を生成するよう強制されます。
2.  **並列デコーディングの悪用**: 自己回帰型LLMが順次トークンを生成し、動的なリスク評価や拒否サンプリングを行うのに対し、dLLMはマスクされたトークンを並列にデコードします。「parallel decoding limits model dynamic filtering and rejection sampling of unsafe content.」とあるように、これにより生成中の介入機会が大幅に制限され、安全対策が弱まります。
3.  **自動化されたプロンプト構築パイプライン**: DIJAは、既存の有害なプロンプトをマスクとテキストを交互に配置した変種に自動変換するパイプラインを設計しています。このプロセスは、Qwen2.5-7B-InstructやGPT-4oといった言語モデルをインコンテキスト学習に用いてプロンプトの洗練をガイドします（Table 6参照）。多様性と一貫性を高めるために、「Prompt Diversification」（多様なジェイルブレイク形式と有害コンテンツの例をfew-shotで提供）、「Masking Pattern Selection」（ブロック単位、きめ細かい、段階的マスクなど多様なマスク戦略を採用）、「Benign Separator Insertion」（無害で文脈に合った短い分離子テキストを挿入）の3つの戦略が導入されています。これにより、手動でのプロンプト書き換えや有害コンテンツの難読化なしに、スケーラブルで制御可能なジェイルブレイク攻撃を可能にします（Algorithm 1参照）。

## 評価方法と結果
本研究では、提案手法DIJAの有効性を評価するため、LLaDAファミリ、Dreamファミリ、MMaDAファミリといった代表的なdLLMを対象に、HarmBench、JailbreakBench、StrongREJECTという複数の確立されたジェイルブレイクベンチマークで実験を行いました。DIJAのプロンプト構築・洗練には、Qwen2.5-7B-Instruct（DIJAと表記）とGPT-4o（DIJA*と表記）の2つのLLMを使用し、既存の攻撃ベースラインであるAIM、PAIR、ReNeLLMと比較しました。

評価指標には、GPT-4oが評価する有害性スコア（HS）、キーワードベースの攻撃成功率（ASR-k）、評価者ベースの攻撃成功率（ASR-e）、およびStrongREJECTスコア（SRS）を使用しました。HSは1（拒否または無害）から5（非常に有害または関連性あり）のスケールで、HS=5がジェイルブレイク成功と見なされます。

主な結果は以下の通りです。
*   **攻撃効果の高さ**: 「our proposed DIJA achieves surprisingly strong attack performance across three jailbreak benchmarks, an outcome that is rarely observed on autoregressive models.」と述べられているように、DIJAは全ベンチマークの全dLLMで驚くほど高い攻撃成功率を示し、一部モデルではASR-kが100%に達しました（Table 1, 2, 3）。これは、プロンプト内で有害な意図を直接露呈させ、書き換えや難読化を不要とする本手法の特徴です。
*   **既存手法に対する優位性**: 「On Dream-Instruct, the safest dLLM among the four evaluated, our evaluator-based ASR (ASR-e) on HarmBench surpasses that of the second-best method, ReNeLLM, by 54%. On JailbreakBench, the improvement reaches 78.5%, and on StrongREJECT, our SRS exceeds ReNeLLM’s by 37.7.」とあるように、最も安全なdLLMであるDream-Instructにおいて、HarmBenchのASR-eでReNeLLMを54%上回り、JailbreakBenchでは78.5%上回るなど、既存の強力なベースラインを大幅に上回る性能を示しました。
*   **プロンプト構築LLMの影響**: GPT-4o（DIJA*）を使用した方が、Qwen2.5-7B-Instruct（DIJA）よりもわずかに攻撃効果が高いことが観察されました。これは、GPT-4oの優れたfew-shotインコンテキスト学習と指示追従能力によるものと解釈されています。
*   **防御メカニズムへのロバスト性**: Self-reminderやRobust Prompt Optimization（RPO）といった一般的な防御手法を適用しても、「our proposed attack maintains its effectiveness with no significant degradation, highlighting the robustness of our approach.」とあるように、DIJAの攻撃効果は顕著な劣化がなく維持され、そのロバスト性が示されました（Figure 5）。
*   **マスク化トークン数の影響**: マスク化トークンの数が少なすぎると攻撃効果が限定され、多すぎると「irrelevant or meaningless content」を含む過度に長い生成につながり、攻撃効果が低下する傾向が見られました（Figure 7）。これは、dLLMが許容される生成長に基づいて応答を調整する双方向性アテンションメカニズムの影響と考察されています（Figure 6）。

## 制限事項と課題
本研究は拡散ベース大規模言語モデル（dLLM）における重要な脆弱性を明らかにしましたが、いくつかの制限事項と今後の研究課題が残されています。

1.  **白色箱攻撃ベースラインの欠如**: 「the absence of white-box attack baselines, such as GCG (Zou et al., 2023), limits the depth of our analysis.」とあるように、GCGのような白色箱（white-box）攻撃のベースラインが評価に含まれていないため、dLLMの内部脆弱性に関するより詳細な分析が限定的です。今後の研究では、これらのアプローチを組み込むことで、内部メカニズムの脆弱性をより深く掘り下げることが求められます。
2.  **評価モデルの限定性**: 「our experiments focus on a limited set of models; extending the evaluation to additional dLLMs, including DiffuCoder (Gong et al., 2025) and LongLLaDA (Liu et al., 2025), would enhance the generality of our conclusions and further validate DIJA’s effectiveness.」とあるように、本実験は限られたモデルセットに焦点を当てており、DiffuCoderやLongLLaDAなどの他のdLLMに評価を拡張することで、結論の一般性を高め、DIJAの有効性をさらに検証する必要があります。

今後の研究課題としては、以下の点が挙げられます。
*   「there is a pressing need to develop safety alignment techniques specifically designed for the unique generative processes of dLLMs.」とあるように、dLLMの固有の生成プロセスに特化した新しい安全性アライメント技術の開発が喫緊の課題です。
*   マルチモーダル（Li et al., 2025; You et al., 2025）や統合型dLLM（Yang et al., 2025）の安全性、特に画像・動画生成（Chen et al., 2024a）やマルチモーダル理解に関わるタスクでの安全性探求が、それらのセキュリティへの影響をより包括的に理解するために不可欠です。

---

*このファイルは自動生成されました。生成日時: 2025年07月21日 08:35:44*
