# PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving

**arXiv ID**: [2507.17596](http://arxiv.org/abs/2507.17596v2)
**PDF**: [ダウンロード](http://arxiv.org/pdf/2507.17596v2.pdf)
**著者**: Maciej K. Wozniak, Lianhang Liu, Yixi Cai, Patric Jensfelt
**カテゴリ**: cs.CV, cs.AI, cs.LG, cs.RO
**公開日**: 2025-07-23T15:28:23Z

---

## 要約

## #0ショートサマリ
本研究は、エンドツーエンド自動運転モデルが抱える、大規模モデル、LiDARセンサー依存、計算集約的なBEV表現といった課題に対処します。特に、カメラのみを搭載した普及型車両への展開を可能にするため、「PRIX（Plan from Raw Pixels）」という効率的なエンドツーエンド運転アーキテクチャを提案しました。PRIXは、視覚特徴抽出器と生成型プランニングヘッドを組み合わせ、生ピクセル入力から直接安全な軌道を予測します。中核要素であるCaRT（Context-aware Recalibration Transformer）モジュールは、マルチレベルの視覚特徴を効果的に強化します。広範な実験により、PRIXがNavSimおよびnuScenesベンチマークで最先端性能を達成し、大規模なマルチモーダル拡散プランナーに匹敵しつつ、推論速度とモデルサイズにおいて大幅に効率的であることを示しました。これにより、PRIXは実世界での展開に実用的なソリューションとなります。

## #1本研究の概要
本研究は、エンドツーエンド自動運転モデルの実用展開を阻む主な課題、すなわち大規模なモデルサイズ、高価なLiDARセンサーへの依存、および計算コストの高いBEV（Bird's-Eye-View）特徴表現を解決することを目的としています。特に、カメラのみを搭載する量産車への技術拡張性を高めることを重視しています。

本研究で達成できたのは、「PRIX（Plan from Raw Pixels）」という新しい効率的なエンドツーエンド運転アーキテクチャの提案と実証です。PRIXは、カメラデータのみを使用し、明示的なBEV表現やLiDARを必要とせずに動作します。その主要なコンポーネントは、視覚特徴抽出器と生成型プランニングヘッドの組み合わせであり、生ピクセル入力から直接安全な軌道を予測します。また、本アーキテクチャの中核をなす「Context-aware Recalibration Transformer (CaRT)」は、頑健なプランニングのためにマルチレベルの視覚特徴を効果的に強化するよう設計された新しいモジュールです。包括的な実験により、PRIXがNavSimおよびnuScenesベンチマークで最先端のパフォーマンスを達成し、より大規模なマルチモーダル拡散プランナーの能力に匹敵しながらも、推論速度とモデルサイズにおいて大幅に効率的であることが示され、実世界での展開に向けた実用的なソリューションとしての可能性が証明されました。

## #2本研究の新規性や貢献
エンドツーエンド自動運転は有望な研究分野ですが、その実用化は大規模なモデルサイズ、高価なLiDARセンサーへの依存、および計算コストの高いBEV特徴表現によって妨げられています。特に、カメラのみを搭載した普及型車両へのスケーラビリティが大きな課題となっています。現在の最先端（SOTA）手法の多くは、カメラとLiDARを融合することで包括的な環境表現を構築していますが、これは高価で計算集約的であり、適用範囲を限定します。また、既存のカメラのみのエンドツーエンドアプローチは、モデルサイズが大きすぎ、計算コストが高く、推論速度が遅いという問題があります。

本研究は、これらの課題に対応するため、「PRIX（Plan from Raw Pixels）」を提案します。PRIXは、カメラデータのみで動作し、LiDARや明示的なBEV特徴表現を必要としない、新規かつ効率的なエンドツーエンド運転アーキテクチャです。
本研究の主な貢献は以下の通りです。
1. **PRIXの導入**: 「カメラのみのエンドツーエンドプランナーであり、推論速度とモデルサイズにおいて、マルチモーダルおよび従来のカメラのみのアプローチよりも大幅に効率的」です。
2. **Context-aware Recalibration Transformer (CaRT)の提案**: 「堅牢なプランニングのためにマルチレベルの視覚特徴を効果的に強化するよう設計された」新しいモジュールです。
3. **包括的なアブレーションスタディ**: モデルのアーキテクチャ選択を検証し、性能、速度、モデルサイズのトレードオフ最適化に関する洞察を提供しました。
4. **SOTA性能の達成**: NavSimおよびnuScenesデータセットで最先端の性能を達成し、大規模なマルチモーダルプランナーを上回り、他のカメラのみのアプローチよりもはるかに小型かつ高速であることを示しました。これにより、カメラのみの自動運転システムにおける新たなベンチマークを確立しました。

## #3手法
本研究で提案されたPRIX（Plan from Raw Pixels）は、生カメラデータから自己車両の最適な将来の軌道を生成するエンドツーエンド自動運転モデルです。

PRIXは、主に以下の2つのコンポーネントで構成されます。
1. **視覚特徴抽出**: 本モデルの基盤は、「軽量なカメラ専用の視覚特徴抽出器」です。これは、「ResNetを階層的なバックボーンとして採用し、異なる解像度で特徴マップ（xi）を自然に抽出」します。特徴マップは、初期層では細かい空間詳細を捉え、深い層では豊かな意味的コンテキストを持つという特徴があります。この課題に対処するため、PRIXは「Context-aware Recalibration Transformer (CaRT)モジュール」を導入します。CaRTモジュールでは、特徴マップxiを適応的平均プーリングにより固定サイズに標準化し、共有重みのマルチヘッド自己注意（SA）ブロックで処理します。SAは空間ドメインにわたる長距離依存関係をモデル化し、「自己注意（Ai）の出力は、再較正された特徴マップであり、元のxi特徴マップにスキップ接続を介して結合され、xc_iとして次のResNet層f_i+1に供給される」ことで、グローバルな意味的コンテキストを注入し、既存の特徴の解釈を根本的に変えます。最終的に、建築はFPN（Feature Pyramid Network）と同様のトップダウンパスウェイで終わり、意味的抽象化と空間的忠実度のバランスをとった包括的な視覚基盤を生成します。

2. **拡散ベースの軌道プランナー**: 「Conditional denoising diffusion head from DiffusionDrive」を採用しています。このアプローチは、軌道予測をノイズ除去プロセスとして扱います。与えられた「ノイズのある軌道提案（アンカー）、自己車両状態、視覚特徴」から、モデルはそれらを「実行可能な計画に徐々に洗練」していきます。軌道は「ウェイポイントのシーケンス」として表現され、ノイズが追加された後、逆プロセスでノイズを除去し元の軌道を回復するよう学習します。このプロセスは、「カメラからの視覚特徴、車両の現在の自己状態、およびノイズのあるアンカー」を結合した文脈ベクトルcによって条件付けられます。

3. **訓練目的**: モデルは、軌道模倣損失（Lplan）だけでなく、補助タスクとして「オブジェクト検出（Ldet）」と「意味的一貫性（Lsem）」を導入したマルチタスク学習パラダイムを採用しています。これにより、「カメラのみの特徴抽出器が、世界に対してより構造化され、意味的に意味のある表現を学習する」よう促され、より堅牢な自動運転が可能になります。総損失はこれら主要な計画タスクと補助目的の重み付き和として定義されます: `L=λplanLplan+λdetLdet+λsemLsem`。

## #4評価方法と結果
本研究では、PRIXの性能を評価するために、NavSim-v1、NavSim-v2、およびnuScenesの3つの主要な自動運転ベンチマークデータセットを使用しました。NavSim-v1およびv2では、それぞれPDMS（Predictive Driver Model Score）とEPDMS（Extended PDM Score）という、安全性と運転性能を統合した複合指標を用いて評価しました。nuScenesでは、オープンループ指標としてL2誤差と衝突率を測定しました。また、モデルの設計選択の妥当性を検証するために、CaRTモジュールの重み共有、アンカーとエンドポイントの組み合わせ、CaRTの有無、拡散ステップ数、損失関数の影響、および異なるプランナーの種類に関する包括的なアブレーションスタディを実施しました。

実験結果は以下の通りです。
- **ベンチマーク性能**:
    - NavSim-v1において、PRIXはPDMS 87.8で最高の性能を達成しました。特筆すべきは、「PRIXがカメラのみのモデルでありながら、同じ入力を使用する他の方法を上回るだけでなく、DRAMAのような豊富なカメラとLiDARデータを備えたモデルをも凌駕した」点です。
    - 最新のNavSim-v2ベンチマークでも、PRIXはEPDMS 84.2で最高の全体スコアを達成しました。特にEC（Engagement Compliance）スコアにおいて、「HydraMDP++を大幅に上回った」と述べられています。
    - nuScenes軌道予測チャレンジでは、「0.57mという最低のL2平均誤差」と「0.07%の最低衝突率」を達成し、既存のすべてのカメラベースのベースラインを上回りました。

- **効率性**:
    - NavSim-v1におけるDiffusionDriveとの比較では、「PRIXが現在のSOTAエンドツーエンドマルチモーダルアプローチであるDiffusionDriveに匹敵する性能（PDMS 87.8 vs 88.1）を達成しながら、25%以上速く動作する（57.0 FPS vs 45.0 FPS）」ことを示しました。また、モデルサイズも37MとDiffusionDriveの60Mより大幅に小さいです。

- **アブレーションスタディ**:
    - **CaRTの重み共有**: CaRTモジュールで自己注意層の重みを共有する設計が、個別のSAを使用する場合よりも高いスコアを達成し、パラメータ数を削減し、推論速度を向上させました。「この単一の自己注意重みセットを異なるレベルの特徴抽象化全体で学習させることで、より堅牢で汎用的な表現が得られる」と考察されています。
    - **CaRTの全体的な影響**: CaRTモジュールを削除すると、モデル性能が大幅に低下する（PDMSが87.8から76.4へ）ことを示し、「自己注意メカニズムが空間的依存関係をモデル化し、チャネルごとの特徴を再較正する上で極めて重要な役割を果たす」ことを確認しました。
    - **拡散ステップ数**: 拡散ステップ数が増加すると性能が低下することを示し、「2ステップが最適」であると結論付けました。
    - **損失の影響**: 計画損失のみのベースライン（PDMS 70.4）に、オブジェクト検出と意味的セグメンテーションの補助タスクを追加することで、PDMSが87.8まで段階的に向上しました。「プランナーの性能は、これらの補助タスクを通じてシーンの意味的に豊かな表現を学習する特徴の品質に直接結合している」と解釈しています。
    - **異なるプランナー**: 最も性能の良い拡散プランナーが最も遅いものの、単純なMLPヘッドやLSTMヘッドでも、わずかな精度低下で高い性能と高速化が可能であることを示しました。「基盤となる重い処理は視覚エンコーダによって処理される」という仮説が裏付けられました。

これらの結果は、PRIXがカメラのみのシステムでありながら、従来のマルチモーダルシステムに匹敵またはそれを超える性能を、より優れた効率性で達成できることを強く支持しています。

## #5制限事項と課題
PRIXは優れた性能と速度を達成していますが、そのカメラのみという性質により、いくつかの制限事項と課題が存在します。

まず、PRIXは「悪天候、オクルージョン（遮蔽物）、およびセンサーの故障やデキャリブレーションに対して脆弱」であると述べられています。これは、視覚情報のみに依存するシステムに共通の課題であり、例えば豪雨や濃霧、あるいは前方の車両による視界の完全な遮蔽といった状況下では、センサーデータの信頼性が低下し、システム全体の性能に悪影響を及ぼす可能性があります。センサーの物理的な損傷や校正のずれも、正確な環境認識とプランニングを妨げる要因となります。

今後の研究課題と展望として、本研究はこれらの堅牢性に関する課題を克服するための二つの主要な道筋を提示しています。
1. **自己教師あり事前学習**: 「大規模なラベルなしデータセットを用いた自己教師あり事前学習」を通じて、バックボーンがよりロバストな特徴を学習できる可能性があります。これにより、様々な環境条件下やデータの欠損・ノイズがある場合でも、モデルがより汎化された表現を獲得し、堅牢性を向上させることが期待されます。
2. **制御ベースのアプローチの組み込み**: 「制御ベースのアプローチを組み込むことで、不確実性をより良く管理し、困難なシナリオでの安全性を向上させることが可能」です。これは、単なる軌道予測だけでなく、車両の動的な制御を考慮に入れることで、予期せぬ状況やセンサーの不確実性下でも、より安全かつ適切に車両を操作する能力を高めることを意味します。

---

*このファイルは自動生成されました。生成日時: 2025年07月28日 08:36:09*
