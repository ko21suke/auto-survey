# Scaling Laws for Optimal Data Mixtures

**arXiv ID**: [2507.09404](http://arxiv.org/abs/2507.09404v1)
**PDF**: [ダウンロード](http://arxiv.org/pdf/2507.09404v1.pdf)
**著者**: Mustafa Shukor, Louis Bethune, Dan Busbridge, David Grangier, Enrico Fini, Alaaeldin El-Nouby, Pierre Ablin
**カテゴリ**: cs.LG
**公開日**: 2025-07-12T21:16:08Z

---

## 要約

## ショートサマリ
本研究は、大規模ファウンデーションモデルの事前学習において、データドメインの混合比（データ混合）の最適化が試行錯誤に依存し、大規模化に伴い非現実的になる問題を解決します。この課題に対し、本研究はスケーリング法則を用いることで、任意のターゲットドメインに対する最適なデータ混合比を系統的に決定する手法を提案します。このアプローチは、モデルサイズN、訓練トークン数D、ドメイン重みベクトルhを用いてモデルの損失を正確に予測します。実験では、大規模言語モデル（LLM）、ネイティブマルチモーダルモデル（NMM）、大規模ビジョンモデル（LVM）の3つの異なる大規模設定で、提案するスケーリング法則の予測能力と外挿能力を実証しました。これにより、少数の小規模な訓練実行から大規模モデルの性能や最適なデータ混合比を推定し、コストのかかる試行錯誤に代わる、原理に基づいた代替手段を提供することに成功しています。

## 本研究の概要
本研究の目的は、大規模ファウンデーションモデルの事前学習におけるデータ混合比の選択という重要な課題を解決することです。これらのモデルは通常、複数のデータドメインで訓練されますが、各ドメインのデータ使用割合（データ混合比）がモデル性能に決定的な役割を果たします。しかし、従来のデータ混合比の選定は「ad-hoc trial and error（アドホックな試行錯誤）」に頼っており、大規模な事前学習においては非効率的かつ非現実的であるという背景がありました。

本研究は、この問題を解決するために、スケーリング法則を拡張し、モデルの損失がモデルサイズN、訓練トークン数D、および特定のドメイン重みベクトルhにどのように依存するかを予測する系統的な手法を提案しました。達成できたこととして、提案するスケーリング法則が、大規模言語モデル（LLM）、ネイティブマルチモーダルモデル（NMM）、大規模ビジョンモデル（LVM）という3つの異なる大規模設定において、その予測能力を普遍的に持つことを検証しました。さらに、「これらのスケーリング法則は、少数の小規模な訓練実行を用いてパラメータを正確に推定でき、より大規模なスケールや未知のドメイン重みに対しても性能を外挿できる」ことを示しました。これにより、「スケーリング法則は、与えられた訓練予算（N, D）の下で任意のターゲットドメインに対する最適なドメイン重みを導き出すことを可能にし、コストのかかる試行錯誤法に代わる原理に基づいた代替手段を提供する」と述べています。

## 本研究の新規性や貢献
本研究は、大規模モデル訓練におけるデータ混合比選択の課題に焦点を当てています。研究分野の現状として、現代の機械学習モデルは多様なデータドメインで事前学習されますが、その際、各ドメインのデータ使用割合（ドメイン重み）の決定は「ad-hoc trial and error（アドホックな試行錯誤）」に依存しており、系統的かつ原理的な方法が欠如しているという課題がありました。

関連する先行研究では、スケーリング法則がモデルの性能と計算資源（パラメータ数Nや訓練トークン数D）の関係を予測する有用なフレームワークを提供してきましたが、「ドメイン重みhが損失にどのように影響するか」については十分に考慮されていませんでした。例えば、Ye et al. [67] や Ge et al. [22] の研究は、固定のNとDに対してhの関数として損失をモデル化していますが、本研究のようにN、D、およびhの相互作用を捉える「joint scaling law（結合型スケーリング法則）」は提案しておらず、また比較的小規模なモデルや単一モダリティに限定されていました。

本研究の位置づけとして、スケーリング法則を「ドメイン重みがモデル性能に与える影響」にまで拡張した点で新規性があります。具体的には、「モデル損失がドメイン重みと訓練トークン数・モデルパラメータ数との相互作用によって予測可能であること」を示しました。これにより、少数の小規模な訓練実行から大規模モデルの損失や最適なドメイン重みを正確に予測・外挿することを可能にし、「 costly trial-and-error methods（コストのかかる試行錯誤法）」に代わる「principled alternative（原理に基づいた代替手段）」を提供することで、大規模モデルの効率的な開発に大きく貢献しています。

## 手法
本研究では、大規模ファウンデーションモデルにおける最適なデータ混合比を決定するための系統的な手法を提案しています。その主要な技術とアプローチは、モデルの損失をモデルサイズN、訓練トークン数D、および特定のドメイン重みベクトルhの関数として予測するスケーリング法則の導入です。

提案するスケーリング法則には、以下の2つの定式化があります。
1.  **Additive scaling law（加算型スケーリング法則）**: 「$L=E+\frac{1}{\sum_{i=1}^k C_i h_i^{\gamma_i}}+A N^\alpha+B D^\beta$」 (Sec 2.2, Eq.4)。この法則では、$E, A, B, \alpha, \beta, C_i, \gamma_i$がパラメータとなります。この法則の特性として、最適なドメイン重み$h^*$はモデルサイズNとトークン数Dに依存しないと仮定されます。
2.  **Joint scaling law（結合型スケーリング法則）**: 「$L=E+\frac{1}{\sum_{i=1}^k C_i h^{\gamma_i}_i+A_h N^\alpha+B_h D^\beta}$ with $A_h=(\sum_{i=1}^k C^A_i h_i)^{\gamma_A}$ and $B_h=(\sum_{i=1}^k C^B_i h_i)^{\gamma_B}$」 (Sec 2.2, Eq.5)。この法則は、$A_h$と$B_h$の項がドメイン重み$h$に依存することで、スケール（N, D）と混合比の間の相互作用を捉えます。これにより、最適な$h^*$が計算予算に依存するという予測を立てます。

これらのスケーリング法則のパラメータをfitting（適合）させるために、異なるN、D、hで実行された複数の訓練から得られたターゲット損失$L_T$を用います。最適パラメータ$Z^*$は、「Huber loss（フーバー損失）」関数「$H(Z) = \frac{1}{p}\sum_{j=1}^p Huber(L_j^T - L(N_j, D_j, h_j; Z))$」 (Sec 2.3, Eq.6) を最小化することで得られます。高次元のパラメータ空間での効率的な最適化を実現するために、本研究では「Basin-hopping algorithm [62]」と「L-BFGS」を組み合わせた手法を使用しています。具体的には、「我々は、初期パラメータZをサンプリングするためにランダムサーチを使用し、次に、損失関数の最小値を探索するためにL-BFGSの代わりにBasin-hoppingアルゴリズムを使用する」 (Sec 2.3) という変更を加えています。

## 評価
本研究の評価は、提案するスケーリング法則の予測能力と、そこから導出される最適なデータ混合比の有効性を検証することに焦点を当てました。

**実験と評価の方法:**
評価は、大規模言語モデル（LLM）、ネイティブマルチモーダルモデル（NMM）、大規模ビジョンモデル（LVM）という3つの大規模なモデル設定で行われました。スケーリング法則のfittingは、少数の小規模モデルと少ない訓練トークン数（例: LLMではNが1.4B以下）の実行データを用いて行われました。その後、これらの法則を、より大規模なモデル（例: LLMではNが3B）や、訓練時には使用されなかった新たなドメイン重みに対する損失予測に外挿し、その精度を評価しました。予測精度は、「Mean Relative Error（MRE、平均相対誤差）」という指標で定量化され、「|prediction - observation| / observation」 (Sec 2.3) としてパーセンテージで報告されました。また、fittingされたスケーリング法則を用いて、特定の訓練予算（N, D）の下で損失を最小化する最適なドメイン重み$h^*$を導出し、その性能を均一な重みや既存の標準的なデータ混合比と比較しました。

**得られた結果の概要と解釈:**
「予測された損失は、結合型法則と加算型法則の両方で観測された値と密接に一致する」 (Sec 4) ことが示され、表2のMRE%でも一貫して低い値が報告されました。特に、「結合型法則は加算型法則よりも改善が見られた」。これは、「小規模でスケーリング法則をフィットさせ、大規模に外挿できることを示している」 (Sec 4) と解釈されています。

最適なデータ混合比については、LLMの実験でOpenHermesデータセットの損失を最小化するよう設計された「$h_{OH}^*$」を用いたモデルが、訓練ドメインの平均損失を最小化する「$h_{avg}^*$」やベースラインモデルと比較して、OpenHermes損失および主要なダウンストリームタスク（CORE、MMLU）で最高の性能を示しました（図4、表3）。研究者は、「この論文で示されたパイプライン — 高品質ドメインにおける損失のスケーリング法則を小規模実行で推定し、その最小値を探索し、それを用いて大規模モデルを訓練する — が、より良いモデルを得るための有望な道筋であると信じている」 (Sec 5, LLM results) と述べています。NMMの実験では、「最適化された混合比は大規模モデルサイズにも効果的に一般化され、小規模実験に基づいて最適な混合比を選択し、それを大規模に外挿する可能性を検証している」 (Sec 5, NMM results) と報告されています。さらに、法則のfittingに必要な訓練実行数についても検証され、「NMMの3ドメインとLLMの4ドメインでは約10回の実行が必要」であり、「LLMの6ドメインと8ドメインでは約20回の実行が必要」 (Sec 6) であることが示されました。

## 制限事項と課題
本研究は、ファウンデーションモデルのデータ混合比最適化において重要な進展を示しましたが、いくつかの制限事項と今後の研究課題を認識しています。

**研究の限界や未解決の問題:**
1.  **事前学習に限定**: 「我々の現在の研究は事前学習に焦点を当てているが、継続的事前学習やファインチューニングも混合比が重要となるシナリオである」 (Sec 8) と述べています。本研究の成果がこれらのシナリオに直接適用できるかは、さらなる検証が必要です。
2.  **損失予測とタスク性能**: 「我々のスケーリング法則は汎用的なターゲット損失を予測するが、これはダウンストリームタスクの性能と相関があることが知られている。今後の研究では、この性能を直接予測することが含まれるかもしれない」 (Sec 8) と指摘されています。汎用損失と具体的なタスク性能との直接的な関連性や予測可能性は、未解決の課題です。
3.  **データ反復の仮定**: 「データ反復がないと仮定している（すなわち、各ドメインからの無限のデータストリーム）が、これは非常に希少な高品質ソースで訓練する場合には非現実的である」 (Sec 8) と述べています。実世界のデータセットでは、データの希少性や品質がデータ反復の必要性を生じさせ、本研究の前提とは異なる状況が生じます。
4.  **固定された混合比**: 「訓練を通じて混合比が固定されていると仮定しているが、将来の研究では重みの動的な進化（例：カリキュラム学習）を検討するかもしれない」 (Sec 8) としており、訓練中にデータ混合比を動的に調整するアプローチの可能性を今後の課題として挙げています。

**今後の研究課題や展望:**
上記の限界を踏まえ、本研究の成果は、事前学習のコスト削減とモデル性能向上への道を開くと同時に、将来的にはダウンストリームタスクの性能直接予測、データ反復を考慮したスケーリング法則の検討、および訓練中の動的なデータ混合比の最適化といった領域へと研究を拡張する可能性を秘めていると結論付けています。

---

*このファイルは自動生成されました。生成日時: 2025年07月16日 08:33:12*
