# PixNerd: Pixel Neural Field Diffusion

**arXiv ID**: [2507.23268](http://arxiv.org/abs/2507.23268v1)
**PDF**: [ダウンロード](http://arxiv.org/pdf/2507.23268v1.pdf)
**著者**: Shuai Wang, Ziteng Gao, Chenhui Zhu, Weilin Huang, Limin Wang
**カテゴリ**: cs.CV
**公開日**: 2025-07-31T06:07:20Z

---

## 要約

## ショートサマリ
本研究は、従来の拡散モデルがVAE（変分オートエンコーダ）の潜在空間に依存し、その2段階訓練パラダイムが累積エラーやデコードアーティファクトを引き起こす問題を解決します。複雑なカスケードパイプラインやトークン数の増加を伴うピクセル空間での挑戦に対し、パッチ単位のデコードをニューラルフィールドでモデル化する「PixNerd」を提案します。これは単一スケール、単一ステージ、効率的なエンドツーエンドソリューションです。実験結果として、ImageNet 256x256で2.15 FID、512x512で2.84 FIDを達成し、VAEや複雑なパイプラインなしで高い性能を示しました。テキスト-画像生成においても、GenEvalベンチマークで0.73、DPGベンチマークで80.9の競争力あるスコアを記録しました。

## 本研究の概要
本研究の目的は、拡散モデルが抱えるVAE依存に起因する課題を解決し、より効率的かつ高品質な画像生成を実現することです。従来のDiffusion Transformersは、画像を圧縮された潜在空間で扱うためにVAEに大きく依存しており、この2段階の訓練パラダイムが累積エラーやデコード時のアーティファクトを引き起こすという問題がありました。一方、直接ピクセル空間で動作する拡散モデルは、広大なピクセル空間を扱うため計算コストが高く、複雑なカスケードパイプラインを必要とする点が課題でした。

これらの問題に対処するため、本研究は、パッチ単位のデコードをニューラルフィールドでモデル化する新しいフレームワーク「PixNerd（Pixel Neural Field Diffusion）」を提案しました。PixNerdは、単一スケール、単一ステージのエンドツーエンドなソリューションであり、VAEを必要としません。

本研究で達成できたことは、ImageNet 256x256で2.15 FID、ImageNet 512x512で2.84 FIDという競争力のある画像生成性能を、複雑なカスケードパイプラインやVAEなしに直接ピクセル空間で実現したことです。さらに、PixNerdフレームワークをテキスト-画像生成アプリケーションにも拡張し、GenEvalベンチマークで0.73、DPGベンチマークで80.9という高い総合スコアを達成し、その汎用性と有効性を示しました。

## 本研究の新規性や貢献
本研究の背景には、拡散モデル、特にDiffusion TransformersがVAE（変分オートエンコーダ）の圧縮された潜在空間に大きく依存しているという研究分野の現状があります。VAEは空間次元を大幅に削減し学習を容易にする一方で、その2段階の訓練パラダイムが「累積エラー」や「不可避なデコードアーティファクト」を導入するという課題を抱えています。

関連する先行研究としては、DiTやSiTなどの潜在拡散モデルが存在しますが、これらはVAEに依存し、その訓練が複雑でデコードアーティファクトの問題を抱えています。また、ADMやPixelflow、Relay Diffusionといったピクセル拡散モデルも研究されていますが、これらは「実用的ではない計算資源」を必要とするか、計算コスト削減のために「複雑なカスケードソリューション」を採用しており、訓練と推論を複雑化させていました。

本研究はこれらの限界に対し、「従来の努力とは対照的に、我々はニューラルフィールドでパッチ単位のデコードをモデル化し、単一スケール、単一ステージ、効率的なエンドツーエンドソリューションであるピクセルニューラルフィールド拡散（PixNerd）を提案します」と述べています。これにより、潜在拡散モデルと同等のトークン数と計算要件を維持しながら、大規模パッチのピクセル空間拡散Transformerの性能上限を探求するという位置づけになります。ニューラルフィールドの採用により、大規模パッチ設定下でのきめ細かい詳細学習の課題を大幅に軽減することに成功しています。

## 手法
本研究の「PixNerd」は、Diffusion Transformerの設計に則りつつ、従来の線形射影をパッチ単位のニューラルフィールドに置き換えることで、ピクセル空間での高解像度画像生成を実現しています。

使用した主要な技術・手法は以下の通りです。まず、「Rectified Flow Model」を採用し、データから標準ガウスノイズへの線形変換を学習することで、速度場 `vθ(xt, t)` を直接予測します。次に、「Diffusion Transformer」アーキテクチャを採用し、画像を非重複パッチに分割して1Dシーケンスに変換し、自己注意およびFFNブロックで処理します。最後に、核心となる「Neural Field」（暗黙的なニューラル表現）を導入し、ピクセル座標エンコーディングから信号をマッピングするMLPとして機能させます。

本研究のアプローチは、潜在拡散モデルと同じトークン数を維持しつつ、ピクセル空間でより大きなパッチサイズを扱うというものです。このため、従来の線形射影では困難だった大規模パッチの詳細な表現を、ニューラルフィールドによって可能にします。

特徴的な技術は「Patch-wise Neural Field」です。これは、Diffusion Transformerの最終隠れ状態 `Xn` を入力として、各パッチに特化したニューラルフィールドMLPの重み `Wn1, Wn2` を予測するものです。「具体的には、我々は各パッチのニューラルフィールドMLPの重み `{Wn1 ∈ RD2×D1, Wn2 ∈ RD1×D2}` を `Xn` から予測します。」とあり、その式は「`Wn1,Wn2=Linear (SiLU (Xn))`」です。次に、パッチ内のピクセル座標 `(i, j)` を座標エンコーディング `PE(i, j)` に変換し、これとノイズ付きピクセル値 `xn(i, j)` を連結してニューラルフィールドMLPに入力し、速度 `Vn(i, j)` を予測します。この処理は「`Vn(i, j) =MLP (Concat ([PE(i, j),xn(i, j)])| {Wn1/||Wn1||,Wn2/||Wn2||})`」と記述されます。最後に、「`vn(i, j) =Linear (Vn(i, j))`」によってピクセルごとの速度 `vn(i, j)` をデコードします。訓練の安定化と性能向上のため、ニューラルフィールドのパラメータには行ごとの正規化が適用されます。また、「Coordinate Encodings」では、「我々のDCT-Basisエンコーディングは、サイン/コサインエンコーディングよりもはるかに良い結果を達成します」と述べられており、`DCT-PE (i, j) ={cos(k1i) cos( k2j),}k1,k2∈(0,K]`が採用されています。

## 評価方法と結果
本研究では、提案手法PixNerdの性能を評価するため、多岐にわたる実験を実施しました。評価は主にImageNet 256x256および512x512におけるクラス条件付き画像生成と、GenEvalおよびDPGベンチマークを用いたテキスト-画像生成で行われました。主要な評価指標にはFID（Fréchet Inception Distance）、sFID、IS（Inception Score）、Precision、Recallが用いられ、テキスト-画像生成では各ベンチマークの総合スコアが報告されました。また、ニューラルフィールドの設計（正規化、チャネル数、MLP層数、座標エンコーディング）と推論スケジューラの設計（Interval Guidance、サンプリングソルバー）に関するアブレーションスタディも行われました。

得られた結果の概要は以下の通りです。
**ImageNetクラス条件付き生成:**
「ImageNet 256×256において、我々のPixNerd-XL/16は類似の計算需要を持つ潜在モデルと同等の2.15 FIDを達成」し、特に「他のピクセル空間生成モデルよりもはるかに良い結果」を示しました。例えば、「Euler-50ステップで2.29 FID」を達成し、「Adams-2-order-solver（Adam2）を使用した場合、PixNerd-XL/16は2.16 FIDを達成し、DiTに匹敵する」と報告されています。さらに、「ImageNet 512×512では、我々のPixNerd-XL/16は2.84 FIDを達成」し、これも他の拡散モデルに匹敵する性能です。

**テキスト-画像生成:**
「我々のPixNerd-XXL/16はGenEvalベンチマークで0.73の総合スコアを達成し、DPGベンチマークで80.9の平均スコアを達成」しました。これにより、Pixelflowなどの他のピクセル生成モデルを大幅に上回る競争力のある性能が示されました。

**リソース消費:**
「我々のPixNerdは、他のピクセル拡散モデルよりもはるかに少ないメモリ消費と低いレイテンシ（ADM-GやPixelFlowよりも約8倍高速）を達成」し、潜在拡散モデルと同等の推論メモリとレイテンシを維持できることが示されました。

**アブレーションスタディ:**
ニューラルフィールドパラメータの「row-wise normalization」、64チャネル、2層MLP、そして「DCT-Basis coordinate encoding」が最適な設定であることが示されました。サンプリングソルバーに関しては、「Adams-2 order solverは、限られたサンプリングステップでEulerソルバーよりも一貫して良い結果を達成」しました。

これらの結果は、ニューラルフィールドの導入により、大規模パッチ設定下でも高精細な詳細を学習できるPixNerdの能力を裏付けています。VAEや複雑なカスケードパイプラインなしに、直接ピクセル空間で競争力のある高解像度画像を生成できることを実証し、効率的なリソース消費と高速な推論速度を両立しています。また、訓練なしで任意の解像度での生成が可能であることも示されました。

## 制限事項と課題
本研究のPixNerdは多くの点で改善を達成しましたが、いくつかの制限事項と課題も残されています。

論文では、「現在のPixNerdは、一部のケースで不明瞭な詳細を示し、図3に示すように、まだ潜在モデルの対応物との間にギャップがあります」と述べられています。具体的には、テキスト-画像生成の視覚化において、「時折、ぼやけた、または不自然なアーティファクトが現れます（例：スチームパンクラボの画像）」。これは、複雑なシーンや特定のテクスチャにおいて、モデルが完全に高品質な画像を生成しきれていないことを示唆しています。

今後の研究課題と展望としては、「適切な後処理（post-training processing）がそのようなアーティファクトを軽減できる可能性」があると示唆されており、「ピクセル空間での後処理を今後の研究として探求する」意向が示されています。また、現在のPixNerdは256x256または512x512の正方形画像にクロップして訓練されており、「ネイティブ解像度[70]またはネイティブアスペクト比での訓練[36, 37, 38]を今後の課題として残しています」と明記されています。著者らは、PixNerdが「シンプルでありながらエレガントなピクセル空間生成モデル」であり、「現在の潜在生成モデルが避けられない2段階構成によるエラーの連鎖」や「VAEの訓練における不安定な敵対的損失によるアーティファクトの導入」といった欠点を克服する「将来的な可能性を秘めている」と考えています。

---

*このファイルは自動生成されました。生成日時: 2025年08月04日 08:35:58*
